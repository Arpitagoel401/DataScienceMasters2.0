{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41fd67e-396e-4ac0-b63c-fb614faf7077",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0799cf3-b7ea-48cf-be1d-7849530a38e0",
   "metadata": {},
   "source": [
    " Polynomial functions are used as kernel functions in machine learning algorithms, including Support Vector Machines (SVMs), to transform the input data into a higher-dimensional space where it becomes linearly separable. Kernel functions compute the inner product between two transformed feature vectors without explicitly computing the transformation. Polynomial kernel functions raise the inner product of the original features to a power, effectively creating polynomial combinations of the original features. This enables SVMs to capture non-linear decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c5314-4870-46ef-a6c5-8b09230644aa",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0d4543-84f5-4b57-a802-ea2997f1f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVC classifier with polynomial kernel\n",
    "svm_poly = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773525e-7e0b-4df0-8b5a-1a92f15b9196",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680272a-a515-43d0-9756-3119bdf60440",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), increasing the value of epsilon affects the number of support vectors. As epsilon determines the width of the margin around the predicted values within which no penalty is incurred, increasing epsilon allows more data points to fall within this margin, potentially reducing the number of support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cf674-49da-48f3-afa3-a38d77d9d4c6",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab747b7-788e-44d6-a457-c93d2699ae77",
   "metadata": {},
   "source": [
    "Choice of Kernel Function: Different kernel functions capture different types of relationships between data points. The choice of kernel function should be based on the problem's characteristics. For example, if the data has non-linear relationships, using a polynomial or Gaussian (RBF) kernel might be suitable.\n",
    "C Parameter: The C parameter trades off correct classification of training examples against maximization of the decision function's margin. Larger values of C allow fewer margin violations but may lead to overfitting, while smaller values of C allow a wider margin but may lead to more margin violations.\n",
    "Epsilon Parameter: Epsilon determines the width of the margin around the predicted values within which no penalty is incurred. Larger values of epsilon increase the margin, potentially reducing the number of support vectors and allowing more flexibility in the model.\n",
    "Gamma Parameter: The gamma parameter defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. A small gamma value implies a large similarity radius and results in a smoother decision boundary, while a large gamma value leads to a more complex decision boundary.\n",
    "Example:\n",
    "\n",
    "If you observe overfitting, you may want to increase the C parameter or decrease the gamma parameter.\n",
    "If the model is too rigid, you may want to increase the epsilon parameter to allow for more flexibility in the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b61efd-58e5-4a06-9c45-5b4023a23f98",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "#### L Import the necessary libraries and load the dataseg\n",
    "#### L Split the dataset into training and testing setZ\n",
    "#### L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "#### L Create an instance of the SVC classifier and train it on the training datW\n",
    "#### L hse the trained classifier to predict the labels of the testing datW\n",
    "#### L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-scoreK\n",
    "#### L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performanc_\n",
    "#### L Train the tuned classifier on the entire dataseg\n",
    "#### L Save the trained classifier to a file for future use.\n",
    "\n",
    "#### You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b487a2-aeea-407c-83fa-47252c3a293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861111111111112\n",
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Best Score: 0.9888695315524585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf'], 'gamma': [0.1, 1, 10]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "best_svm = grid_search.best_estimator_\n",
    "best_svm.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(best_svm, 'svm_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e31a5-766b-407e-89bf-2f51773352ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
