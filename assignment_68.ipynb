{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bf4f8e-229a-4c0e-bc9b-517aa4da5834",
   "metadata": {},
   "source": [
    "#### Q1. What is the KNN algorithm?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf054521-a2f3-45b5-b9d9-48fda7149744",
   "metadata": {},
   "source": [
    "KNN, or k-nearest neighbors, is a supervised machine learning algorithm used for both classification and regression tasks.\n",
    "It works on the principle of finding the k nearest data points to a given query point and using them to make predictions.\n",
    "For classification, the predicted class is determined by majority voting among the k nearest neighbors.\n",
    "For regression, the predicted value is typically the average (or weighted average) of the target values of the k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ff759-a2ed-4657-9aad-c8546ddeaf4d",
   "metadata": {},
   "source": [
    "#### Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045947d-4086-41d7-be84-5cdbcc9f9b8b",
   "metadata": {},
   "source": [
    "The value of K in KNN is typically chosen through cross-validation.\n",
    "A smaller value of K may lead to overfitting, while a larger value may lead to underfitting.\n",
    "It's common to try different values of K and choose the one that gives the best performance on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53542db-6df5-4934-bc62-82e6e8cdcdb5",
   "metadata": {},
   "source": [
    "#### Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c2b32-4cbe-43e8-84fd-82ca2475ec5b",
   "metadata": {},
   "source": [
    "KNN classifier is used for classification tasks, where the output is a class label. It predicts the class of a data point based on the majority class among its k nearest neighbors.\n",
    "KNN regressor is used for regression tasks, where the output is a continuous value. It predicts the value of a data point based on the average (or weighted average) of the target values of its k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203adc20-47da-4d08-9980-fe1df441761a",
   "metadata": {},
   "source": [
    "#### Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69ef6b-f1f7-4b8d-801e-9b2c86b0e7ab",
   "metadata": {},
   "source": [
    "The performance of KNN can be measured using various metrics depending on the task, such as accuracy, precision, recall, F1-score (for classification), and mean squared error (for regression).\n",
    "\n",
    "Cross-validation can also be used to estimate the generalization performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d7343-f8f9-44a0-8358-f019c322c56d",
   "metadata": {},
   "source": [
    "#### Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467260f-28d1-4646-bdbd-e2ffb60cf158",
   "metadata": {},
   "source": [
    "The curse of dimensionality refers to the problem where the performance of KNN deteriorates as the number of features (dimensions) in the dataset increases.\n",
    "    \n",
    "As the number of dimensions increases, the distance between data points becomes less meaningful, making it harder to find meaningful neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffde44-7dfa-46d5-9081-eb9ab46f2a0e",
   "metadata": {},
   "source": [
    "#### Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400dbd6-e27f-4d06-9d6d-14bd1cbf5a79",
   "metadata": {},
   "source": [
    "One common approach to handling missing values in KNN is to impute them using the mean, median, or mode of the feature values.\n",
    "Another approach is to ignore data points with missing values during the distance calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436b275-f478-4d6a-9a8d-91c48d645874",
   "metadata": {},
   "source": [
    "#### Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e625c-a0d9-4aab-a79b-42e627db2056",
   "metadata": {},
   "source": [
    "KNN classifier is suitable for classification problems, especially when the decision boundary is nonlinear and the data is not linearly separable.\n",
    "    \n",
    "KNN regressor is suitable for regression problems, especially when the relationship between the features and the target variable is nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d4d46-d236-400a-a9ed-c41642b9279f",
   "metadata": {},
   "source": [
    "#### Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a3be9-5e04-4173-bc31-78f4d861df0b",
   "metadata": {},
   "source": [
    "Strengths: Simple and easy to understand, works well with small datasets, and can capture complex relationships.\n",
    "    \n",
    "Weaknesses: Computationally expensive, sensitive to the choice of K and distance metric, and performs poorly with high-dimensional data.\n",
    "\n",
    "These weaknesses can be addressed by using dimensionality reduction techniques, optimizing the choice of K and distance metric, and scaling the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7978395-f5d7-4185-98d4-0833c429dff3",
   "metadata": {},
   "source": [
    "#### Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de4319-82d3-4d2d-ab49-6dbefe7d6f1a",
   "metadata": {},
   "source": [
    "Euclidean distance: Measures the straight-line distance between two points in a multidimensional space.\n",
    "    \n",
    "Manhattan distance: Measures the distance between two points by summing the absolute differences of their coordinates along each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfaadac-58cc-427c-8061-ddcc3f56d525",
   "metadata": {},
   "source": [
    "#### Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5f7c9-5d42-44f5-b958-e3e0cb5ba7e7",
   "metadata": {},
   "source": [
    "- Feature scaling is important in KNN because it ensures that all features contribute equally to the distance calculation.\n",
    "- Without feature scaling, features with larger scales may dominate the distance calculation, leading to biased results.\n",
    "- Common techniques for feature scaling include standardization (z-score normalization) and min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b8ad2-d574-4196-93ab-79fe415cf033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
