{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4aeb80",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0b8053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Age\n",
      "0   25\n",
      "1   30\n",
      "2   35\n",
      "3   40\n",
      "4   45\n",
      "\n",
      "Scaled Data:\n",
      "    Age\n",
      "0  0.00\n",
      "1  0.25\n",
      "2  0.50\n",
      "3  0.75\n",
      "4  1.00\n"
     ]
    }
   ],
   "source": [
    "#Min-Max scaling, also known as Min-Max normalization, is a data preprocessing technique used to transform numerical features to \n",
    "# a specific range, typically between 0 and 1. \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Example dataset\n",
    "data = {'Age': [25, 30, 35, 40, 45]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Display the original and scaled data\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"\\nScaled Data:\")\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188c504",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d8ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Vector scaling, also known as Normalization, is a feature scaling technique that transforms the values of numerical \n",
    "# features to a unit vector, meaning that the magnitude of each data point becomes 1. \n",
    "\n",
    "# While Min-Max scaling compresses the values to a specific range (e.g., between 0 and 1), Unit Vector scaling maintains the \n",
    "# direction of the data points but ensures that the magnitude is 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331fc4d",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea54745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA) is a dimensionality reduction technique that is commonly used to transform high-dimensional\n",
    "# data into a lower-dimensional representation while preserving the most important information in the data.\n",
    "\n",
    "# Compute the Covariance Matrix: Calculate the covariance matrix of the original data, which represents the relationships \n",
    "# between different features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa829b",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f8f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA is a technique commonly used for feature extraction.In the context of PCA, feature extraction refers to transforming the \n",
    "# original features into a set of new features (principal components) that capture the most important information in the data.\n",
    "# Example:\n",
    "# Consider a dataset with a large number of features representing different aspects of a system. Applying PCA for feature \n",
    "# extraction allows you to identify the most influential features and reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314494e6",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c6be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After applying Min-Max scaling, the values for each feature will be transformed to the range [0, 1], making them comparable \n",
    "# and suitable for input to recommendation algorithms. The scaled features help ensure that no single feature dominates the \n",
    "# recommendation process due to differences in their original scales.\n",
    "# Formula :\n",
    "#     Xscaled = (X - Xmin)/(Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8eb158",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a11827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing:\n",
    "# Standardize the features to ensure consistency.\n",
    "# Applying PCA:\n",
    "# Calculate the covariance matrix.\n",
    "# Compute eigenvectors and eigenvalues.\n",
    "# Sort eigenvectors by eigenvalues.\n",
    "# Select the top k eigenvectors as principal components.\n",
    "# Projection:\n",
    "# Project the original data onto the selected principal components.\n",
    "# Reduced Dimensionality Dataset:\n",
    "# Obtain a reduced-dimensional dataset capturing essential information.\n",
    "# Model Training and Prediction:\n",
    "# Train and evaluate prediction models using the reduced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa6099",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b099b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Values: [ 1  5 10 15 20]\n",
      "Min-Max Scaled Values: [0.         0.21052632 0.47368421 0.73684211 1.        ]\n",
      "Final Scaled Values (Range: -1 to 1): [-1.         -0.57894737 -0.05263158  0.47368421  1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given dataset\n",
    "original_values = np.array([1, 5, 10, 15, 20])\n",
    "\n",
    "# Min-Max scaling\n",
    "X_min = np.min(original_values)\n",
    "X_max = np.max(original_values)\n",
    "\n",
    "# Apply Min-Max scaling formula\n",
    "X_scaled = (original_values - X_min) / (X_max - X_min)\n",
    "\n",
    "# Adjust scaled values to the range of -1 to 1\n",
    "X_final = 2 * X_scaled - 1\n",
    "\n",
    "# Display the original, scaled, and final values\n",
    "print(\"Original Values:\", original_values)\n",
    "print(\"Min-Max Scaled Values:\", X_scaled)\n",
    "print(\"Final Scaled Values (Range: -1 to 1):\", X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103c860",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35936ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Eigenvectors and Eigenvalues:\n",
    "\n",
    "# Compute the covariance matrix of the dataset.\n",
    "# Find the eigenvectors and eigenvalues of the covariance matrix.\n",
    "# Sort Eigenvectors:\n",
    "\n",
    "# Sort the eigenvectors based on their corresponding eigenvalues in descending order.\n",
    "# Cumulative Explained Variance:\n",
    "\n",
    "# Calculate the cumulative explained variance by summing the sorted eigenvalues.\n",
    "# Decide on the Number of Components:\n",
    "\n",
    "# Choose the number of principal components that explain a significant percentage of the total variance (e.g., 95% or 99%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6d87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
